# DSC-AS
Abstract: Deep subspace clustering achieves better performance than traditional clustering by jointly performing self-expressive feature learning and cluster assignment. Although a large number of deep subspace clustering algorithms have emerged in various applications, most of them fail to learn precise cluster-oriented features. Aiming at the problem that the deep subspace clustering method is not accurate enough in learning the feature representation of the cluster, which affects the final clustering performance, it is proposed to use random displacement and rotation to enhance the original sample data, and use the enhanced samples alternately for training and optimization. Autoencoders and update the cluster assignments of samples, thereby learning robust feature representations. In the fine-tuning stage, the goal of each augmented sample in the loss function is to assign the original sample to the center of the cluster, the calculation of the target may be wrong, and the wrong sample will mislead the auto-encoder network. Adaptive self-paced learning of hyperparameters to select the most convincing samples in each iteration to improve generalization. Experiments were performed on MNIST、USPS、COIL100 datasets, which verified the superior performance when dealing with samples with incorrect target calculation and misleading the encoder network training problem, the effectiveness of the algorithm is further verified by ablation studies and sensitivity analysis.

Keywords: clustering; deep learning; subspace clustering; data augmentation; adaptive self-paced learning
